{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15592965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn .model_selection import train_test_split\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "SEED = 2460686032\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "a27ed5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv(\"iris.data\", header=None)\n",
    "    df.columns = ['Sepal Length', 'Sepal Width', 'Petal Length', 'Petal Width', 'Class']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "7e71151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_data(df):\n",
    "    # converts the dataframe into list\n",
    "    data = df.values.tolist()\n",
    "\n",
    "    # prepares 3 list for each type\n",
    "    data_setosa = []\n",
    "    data_versicolor = []\n",
    "    data_virginica = []\n",
    "\n",
    "    # assigns each to its list accordingly\n",
    "    for datum in data:\n",
    "        if datum[4] == \"Iris-setosa\":\n",
    "            data_setosa.append(datum)\n",
    "        elif datum[4] == \"Iris-versicolor\":\n",
    "            data_versicolor.append(datum)\n",
    "        elif datum[4] == \"Iris-virginica\":\n",
    "            data_virginica.append(datum)\n",
    "            \n",
    "    # divides the data into input and label\n",
    "    X_setosa = [row[:4] for row in data_setosa] # gets first 4 columns as input \n",
    "    Y_setosa = [row[4] for row in data_setosa] # class label as last column\n",
    "\n",
    "    # randomly divides each data by 50/50 train and test while maintaining class balance\n",
    "    x_setosa_train, x_setosa_test, y_setosa_train, y_setosa_test = train_test_split(X_setosa, Y_setosa, test_size = 0.5, random_state=SEED, shuffle=True)\n",
    "\n",
    "\n",
    "    X_versicolor = [row[:4] for row in data_versicolor] # gets first 4 columns as input \n",
    "    Y_versicolor = [row[4] for row in data_versicolor] # class label as last column\n",
    "\n",
    "    x_versicolor_train, x_versicolor_test, y_versicolor_train, y_versicolor_test = train_test_split(X_versicolor, Y_versicolor, test_size = 0.5, random_state=SEED, shuffle=True)\n",
    "\n",
    "\n",
    "    X_virginica = [row[:4] for row in data_virginica] # gets first 4 columns as input \n",
    "    Y_virginica = [row[4] for row in data_virginica] # class label as last column\n",
    "\n",
    "    x_virginica_train, x_virginica_test, y_virginica_train, y_virginica_test = train_test_split(X_virginica, Y_virginica, test_size = 0.5, random_state=SEED, shuffle=True)\n",
    "\n",
    "    random.seed(SEED)\n",
    "    # merges back the dataset into general x train, y train, x test and y test\n",
    "    X_train = x_setosa_train + x_versicolor_train + x_virginica_train\n",
    "    Y_train = y_setosa_train + y_versicolor_train + y_virginica_train\n",
    "\n",
    "    #shuffles while keeping the order\n",
    "    combined_train = list(zip(X_train, Y_train))\n",
    "    random.shuffle(combined_train)\n",
    "    X_train, Y_train = zip(*combined_train)\n",
    "\n",
    "\n",
    "    X_test = x_setosa_test + x_versicolor_test + x_virginica_test\n",
    "    Y_test = y_setosa_test + y_versicolor_test + y_virginica_test\n",
    "    combined_test = list(zip(X_test, Y_test))\n",
    "    random.shuffle(combined_test)\n",
    "    X_test, Y_test = zip(*combined_test)\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "00d66c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# euclidean distance calculation function \n",
    "def calculate_euclidean_dst(x1, x2):\n",
    "    total_sum = 0\n",
    "    for i, j in zip(x1, x2):\n",
    "        total_sum += (i - j) ** 2\n",
    "    return np.sqrt(total_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ab00ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classify(X_train, Y_train, X_test, Y_test, K):\n",
    "    # KNN logic\n",
    "    predictions = []\n",
    "    # calculates euclidean distance from new x_test point to all points in training set\n",
    "    # gets K least distances and gets the majority label class of those and saving it into the prediction list\n",
    "    for x_test in X_test:\n",
    "        euclidean_dsts = []\n",
    "        for index, x_train in enumerate(X_train):\n",
    "            euclidean_dsts.append([index, calculate_euclidean_dst(x_test, x_train)])\n",
    "        euclidean_dsts = sorted(euclidean_dsts, key=lambda x: x[1])\n",
    "        euclidean_dsts = euclidean_dsts[:K]\n",
    "        \n",
    "        nearest_neighbor_label = []\n",
    "        for dst in euclidean_dsts:\n",
    "            nearest_neighbor_label.append(Y_train[dst[0]])\n",
    "            \n",
    "        #gets majority label of K nearest neighbor    \n",
    "        counter = Counter(nearest_neighbor_label)\n",
    "        predictions.append(counter.most_common(1)[0][0])\n",
    "        \n",
    "    # evaluation part\n",
    "    if len(Y_test) == len(predictions):\n",
    "        print(\"Prediction size matches with ground truth labels\")\n",
    "    else:\n",
    "        print(\"Prediction size did not match with ground truth labels!\")\n",
    "        \n",
    "    sample_size = len(Y_test)\n",
    "    correct_prediction = 0\n",
    "    for prediction, y_test in zip(predictions, Y_test):\n",
    "        if prediction == y_test:\n",
    "            correct_prediction += 1\n",
    "\n",
    "    accuracy = correct_prediction / sample_size\n",
    "    print(f\"KNN Accuracy:{accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314cfaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction size matches with ground truth labels\n",
      "KNN Accuracy:0.9733333333333334\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf6a5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()\n",
    "X = df.iloc[:, :-1]\n",
    "X\n",
    "\n",
    "Y = df.iloc[:,-1]\n",
    "Y\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(Y_train))\n",
    "\n",
    "print(len(X_test))\n",
    "print(len(Y_test))\n",
    "\n",
    "\n",
    "print(X_train[74])\n",
    "print(Y_train[74])\n",
    "\n",
    "print(X_test[5])\n",
    "print(Y_test[5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
